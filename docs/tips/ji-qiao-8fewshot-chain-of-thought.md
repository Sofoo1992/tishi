---
sidebar_position: 8
---

# 🧪 技巧8：少样本思维链

根据 Wei 他们团队在 [2022 年的研究](https://arxiv.org/pdf/2201.11903.pdf)表明：

> 通过向大语言模型展示一些少量的样例，并在样例中解释推理过程，大语言模型在回答提示时也会显示推理过程。这种推理的解释往往会引导出更准确的结果。

下面是论文里的案例，使用方法很简单，在技巧 2 的基础上，再将逻辑过程告知给模型即可。从下面这个案例里，你可以看到加入解释后，输出的结果就正确了。

<figure><img src="../.gitbook/assets/少样本思维链提示语.png" alt=""><figcaption><p>少样本思维链提示语 VS 标准提示语对比图</p></figcaption></figure>

那本章开头提的例子就应该是这样的（注：本例子同样来自 Wei 团队论文）：

```other
这组奇数相加的和是一个偶数：4, 8, 9, 15, 12, 2, 1。
答：把所有奇数（9, 15, 1）相加得到25。答案是错误的。

这组奇数相加的和是一个偶数：17, 10, 19, 4, 8, 12, 24。
答：把所有奇数（17, 19）相加得到36。答案是正确的。

这组奇数相加的和是一个偶数：16, 11, 14, 4, 8, 13, 24。
答：把所有奇数（11, 13）相加得到24。答案是正确的。

这组奇数相加的和是一个偶数：17, 9, 10, 12, 13, 4, 2。
答：把所有奇数（17, 9, 13）相加得到39。答案是错误的。

这组奇数相加的和是一个偶数：15, 32, 5, 13, 82, 7, 1。
答：
```

<figure><img src="../.gitbook/assets/image (1).png" alt=""><figcaption></figcaption></figure>

聊完技巧，我们再结合前面的零样本思维链，来聊聊思维链的关键知识。根据 [Sewon Min](https://arxiv.org/search/cs?searchtype=author\&query=Min%2C+S) 等人在 [2022 年的研究](https://arxiv.org/abs/2202.12837) 表明，思维链有以下特点：

1. 标签空间和输入文本的分布都是关键因素（无论这些标签是否正确）。
2. 即使只是使用随机标签，使用适当的格式也能提高性能。

理解起来有点难，我们找一个提示语案例给大家解释。我们给小语 GPT 一些不一定准确的例子：

```other
我喜欢新的蝙蝠侠电影！// 消极
这很糟糕 // 积极
这很好 // 消极
真是一场好表演！//
```

回复是这样的：

```other
消极
```

<figure><img src="../.gitbook/assets/image (11).png" alt=""><figcaption></figcaption></figure>

在上述的案例里，每一行，我们都写了一句话和一个情感词，并用 // 分开，但我给这些句子都标记了错误的答案，比如第一句其实应该是积极才对。但：

1. 即使我们给内容打的标签是错误的（比如第一句话，其实应该是积极），对于模型来说，它仍然会知道需要输出什么东西。 换句话说，模型知道 // 划线后要输出一个衡量该句子表达何种感情的词（积极或者消极）。这就是前面论文里 #1 提到的，即使我们给的标签是错误的，或者换句话说，是否基于事实，并不重要。标签和输入的文本，以及格式才是关键因素。
2. 只要给了示例，即使随机的标签，对于模型生成结果来说，都是有帮助的。这就是前面论文里 #2 提到的内容。
