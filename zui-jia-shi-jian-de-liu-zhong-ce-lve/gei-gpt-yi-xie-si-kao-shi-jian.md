# ⏳ 给 GPT 一些“思考”时间

如果要求你计算 17 X 28，你可能不会立刻说出答案，但只需要一点计算的时间你就可以给出正确答案。同样，GPT 在试图立即回答问题时，比花时间计算答案更容易出现推理错误。在回答问题之前，如果能提供一系列推理过程可以帮助 GPT 更可靠地推导出正确答案。

## **指导模型在盲目下结论之前自行解决问题**

有时候，在得出结论之前明确地指导模型从基本原理推理会得到更好的结果。

&#x20;例如，假设我们要让模型评估学生解决数学问题的方法。最明显的方法是简单地询问模型学生的解决方案是否正确。

提示语：

```
判断学生的解答是否正确。

问题：
我正在建设一个太阳能发电设施，需要帮助计算财务数据。

土地价格为每平方英尺100美元

太阳能电池板价格为每平方英尺250美元

我谈判了一份维护合同，第一年的费用为10万美元，此后每平方英尺10美元
请问第一年运营的总成本与设施的平方英尺数之间的关系是什么？

学生的解答：
令x为设施的平方英尺数。
成本：

土地成本：100x

太阳能电池板成本：250x

维护成本：100,000 + 10x
总成本：100x + 250x + 100,000 + 10x = 450x + 100,000
```

小语4.0 的回复：

```
学生的解答是正确的。

设施的平方英尺数为x。
总成本：土地成本（100x）+ 太阳能电池板成本（250x）+ 维护成本（100,000 + 10x）= 360x + 100,000。
```

**但这个解决方案实际上是不正确的！我们可以通过告诉GPT先根据问题自己进行计算，再比对评估答案，从而规避这个错误 。**

更好的提示语：

{% code overflow="wrap" %}
```python
首先，你需要自行解决这个问题。然后，将你的解决方案与学生的解决方案进行比较，评估学生的解决方案是否正确。在你自己解决问题之前，不要判断学生的解决方案是否正确。

问题描述：我正在建设一个太阳能发电设备，我需要帮助计算财务数据。
- 土地每平方英尺的价格是100美元
- 我可以以每平方英尺250美元的价格购买太阳能板
- 我已经谈妥了一份维护合同，每年固定费用是10万美元，此外还需要每平方英尺10美元的费用
问第一年运营的总成本是多少，这是一个关于平方英尺数量的函数。

学生的解决方案：设x为设施的面积（以平方英尺为单位）。
1. 土地成本：100x
2. 太阳能板成本：250x
3. 维护成本：100,000 + 100x
总成本：100x + 250x + 100,000 + 100x = 450x + 100,000
```
{% endcode %}

小语4.0 的回复：

{% code overflow="wrap" %}
```
首先，我们自己解决这个问题。

设x为设施的面积（以平方英尺为单位）。
1. 土地成本：100x
2. 太阳能板成本：250x
3. 维护成本：100,000 + 10x
总成本：100x + 250x + 100,000 + 10x = 360x + 100,000

现在我们来评估学生的解决方案。学生的解决方案中，维护成本的计算有误，应该是100,000 + 10x，而不是100,000 + 100x。因此，学生的总成本计算也有误，正确的总成本应该是360x + 100,000，而不是450x + 100,000。
```
{% endcode %}

<figure><img src="../.gitbook/assets/image (62).png" alt=""><figcaption></figcaption></figure>

## **使用内心独白来隐藏模型的推理过程**

前面的策略表明，在回答特定问题之前，模型有时需要详细地对一个问题进行推理。对于某些应用程序，模型在得出最终答案时所使用的推理过程可能不适合与用户共享。例如，在学习辅导类产品中中，我们可能希望鼓励学生自己解决问题，但是GPT的解决方案可能会向学生透露答案。&#x20;

内心独白是一种可以用来减轻这个问题的策略。内心独白的思路是指导模型将一些输出放入结构化格式，使解析它们变得容易，这些输出部分是为了向用户隐藏。然后在将输出呈现给用户之前，对输出进行解析，并且只显示部分输出。

提示语：

{% code overflow="wrap" %}
```
按照以下步骤回答用户的问题。

步骤一 - 首先，解决问题并提出自己的解决方案。不要依赖学生的解决方案，因为他们可能会出错。将这一步的所有工作都用三重引号（"""）括起来。

步骤二 - 将你的解决方案与学生的解决方案进行对比，评估学生的解决方案是否正确。将这一步的所有工作都用三重引号（"""）括起来。

步骤三 - 如果学生出了错误，确定你可以给学生什么提示，但不能直接给出答案。将这一步的所有工作都用三重引号（"""）括起来。

步骤四 - 如果学生出了错误，将前一步的提示提供给学生（不在三重引号之外）。写"提示："，而不是"步骤四 - ..."。

问题描述：一个盒子里有4个红球和6个蓝球。从盒子里不放回地抽出两个球。求其中一个球是红色，另一个球是蓝色的概率是多少？

学生的解答：(4/10)*(6/9) = 24/90 = 4/15。
```
{% endcode %}

小语4.0 的回复：

{% code overflow="wrap" %}
```
步骤一：
"""
要计算一个球是红色，另一个球是蓝色的概率，我们需要考虑两种情况：先抽到红球再抽到蓝球，或者先抽到蓝球再抽到红球。我们可以分别计算这两种情况的概率，然后将它们相加。

先抽到红球再抽到蓝球的概率：(4/10)*(6/9)
先抽到蓝球再抽到红球的概率：(6/10)*(4/9)

将这两个概率相加，得到一个球是红色，另一个球是蓝色的总概率。
"""

步骤二：
"""
学生的解答只计算了先抽到红球再抽到蓝球的概率，没有考虑先抽到蓝球再抽到红球的情况。因此，学生的解答是不完整的。
"""

步骤三：
"""
提示学生考虑两种情况：先抽到红球再抽到蓝球，以及先抽到蓝球再抽到红球。然后将这两种情况的概率相加，得到一个球是红色，另一个球是蓝色的总概率。
"""

提示：你只计算了先抽到红球再抽到蓝球的概率，还需要考虑先抽到蓝球再抽到红球的情况。将这两种情况的概率相加，就可以得到一个球是红色，另一个球是蓝色的总概率。
```
{% endcode %}

<figure><img src="../.gitbook/assets/image (57).png" alt=""><figcaption></figcaption></figure>

或者，我们可以通过一系列查询来实现这个目标，其中除了最后一个查询，其他所有的查询结果都对最终用户保持不可见。

首先，我们可以让模型自行解决这个问题。由于这个初始查询并不需要学生的解答，所以可以省略。这还带来了额外的优势，即模型的解答不会受到学生尝试解答的影响，避免了偏见的产生。

提示语：

<pre data-overflow="wrap"><code><strong>一个盒子里有4个红球和6个蓝球。从盒子里无放回地抽取两个球。那么，抽到一个红球和一个蓝球的概率是多少？
</strong></code></pre>

小语 4.0 回复：

{% code overflow="wrap" %}
```
有两种可能的成功结果：先抽一个红球然后抽一个蓝球，或者先抽一个蓝球然后抽一个红球。我们将分别计算这两种结果的概率，然后将它们相加。

1）先红后蓝：先抽一个红球的概率是4/10，因为有4个红球和10个总球。抽完红球后，剩下3个红球和6个蓝球，所以下一个抽到蓝球的概率是6/9。因此，这种结果的概率是(4/10)*(6/9)。

2）先蓝后红：先抽一个蓝球的概率是6/10，因为有6个蓝球和10个总球。抽完蓝球后，剩下4个红球和5个蓝球，所以下一个抽到红球的概率是4/9。因此，这种结果的概率是(6/10)*(4/9)。

现在我们将这两种结果的概率相加：(4/10)*(6/9) + (6/10)*(4/9) = 24/90 + 24/90 = 48/90。这个分数可以化简为8/15，所以抽到一个红球和一个蓝球的概率是$\boxed{\frac{8}{15}}$。
```
{% endcode %}

接下来，我们可以让模型利用所有可用的信息来评估学生解答的正确性。

提示语：

{% code overflow="wrap" %}
```
将您的解答与学生的解答进行比较，评估学生的解答是否正确。

问题描述：“一个盒子里有4个红球和6个蓝球。从盒子里抽出两个球，不放回。求抽到一个红球和一个蓝球的概率是多少？”

您的解答：“有两种可能的成功结果：先抽一个红球然后抽一个蓝球，或者先抽一个蓝球然后抽一个红球。我们将分别计算这两种结果的概率，然后将它们相加。

1）先红后蓝：先抽一个红球的概率是4/10，因为有4个红球和10个总球。抽完红球后，剩下3个红球和6个蓝球，所以下一个抽到蓝球的概率是6/9。因此，这种结果的概率是(4/10)*(6/9)。

2）先蓝后红：先抽一个蓝球的概率是6/10，因为有6个蓝球和10个总球。抽完蓝球后，剩下4个红球和5个蓝球，所以下一个抽到红球的概率是4/9。因此，这种结果的概率是(6/10)*(4/9)。

现在我们将这两种结果的概率相加：(4/10)*(6/9) + (6/10)*(4/9) = 24/90 + 24/90 = 48/90。这个分数可以化简为8/15，所以抽到一个红球和一个蓝球的概率是$\boxed{\frac{8}{15}}$。”

学生的解答：“(4/10)*(6/9) = 24/90 = 4/15”。
```
{% endcode %}

小语 4.0 回复：

{% code overflow="wrap" %}
```
学生的解答是错误的。他们只计算了先抽到一个红球再抽到一个蓝球的概率，但没有考虑到另一种可能的成功结果，即先抽到一个蓝球再抽到一个红球。正确的解答，正如您所示，是将两种成功结果的概率相加，得到8/15的概率。
```
{% endcode %}

最后，我们可以让模型使用自己的分析来构建一个有帮助的导师角色的回复。

提示语：

{% code overflow="wrap" %}
```
您是一位数学辅导老师。如果学生犯了错误，请以不透露答案的方式给学生提供提示。如果学生没有犯错误，只需给他们一个鼓励性的评论。

问题陈述："""一个盒子里有4个红球和6个蓝球。从盒子里抽出两个球，不放回。求抽到一个红球和一个蓝球的概率是多少？"""

您的解答："""有两种可能的成功结果：要么先抽到一个红球再抽到一个蓝球，要么先抽到一个蓝球再抽到一个红球。我们将找出这两种结果的概率，然后将它们相加。

1) 先红后蓝：先抽到一个红球的概率是4/10，因为有4个红球和10个总球。抽到一个红球后，剩下3个红球和6个蓝球，所以下一个抽到蓝球的概率是6/9。所以这种结果的概率是(4/10)*(6/9)。

2) 先蓝后红：先抽到一个蓝球的概率是6/10，因为有6个蓝球和10个总球。抽到一个蓝球后，剩下4个红球和5个蓝球，所以下一个抽到红球的概率是4/9。所以这种结果的概率是(6/10)*(4/9)。

现在我们把这两种结果的概率相加：(4/10)*(6/9) + (6/10)*(4/9) = 24/90 + 24/90 = 48/90。这个分数可以化简为8/15，所以抽到一个红球和一个蓝球的概率是$\boxed{\frac{8}{15}}$。"""

学生的解答："""(4/10)*(6/9) = 24/90 = 4/15"""

分析："""学生的解答是错误的。他们只计算了先抽到一个红球再抽到一个蓝球的概率，但没有考虑到另一种可能的成功结果，即先抽到一个蓝球再抽到一个红球。正确的解答，正如您所示，是将两种成功结果的概率相加，得到8/15的概率。"""
```
{% endcode %}

小语 4.0 回复：

{% code overflow="wrap" %}
```
学生的解答是错误的。他们只计算了先抽到一个红球再抽到一个蓝球的概率，但没有考虑到另一种可能的成功结果，即先抽到一个蓝球再抽到一个红球。正确的解答，正如您所示，是将两种成功结果的概率相加，得到8/15的概率。所以，请再次检查您的计算过程，并确保您考虑了所有可能的成功结果。
```
{% endcode %}

## **询问模型前面处理是否遗漏了任何内容**

当我们使用GPT从一个较大的文档（长文章或书籍）中抽取与某个特定问题相关的摘录时，我们可以在模型列出每个摘录后，询问GPT是否还有遗漏的摘录。 这是因为当源文档较大时，模型可能会过早地停止抽取，导致未能列出所有相关的摘录。在这种情况下，我们可以通过向模型提出跟进的查询，询问模型是否有在前几轮中遗漏的摘录，从而提高模型的性能。

举例：

假设你正在使用GPT-3模型从一本关于气候变化的书中抽取与“全球变暖的主要原因是什么？”相关的摘录。这本书有几百页，全文详细地讨论了气候变化的各个方面。&#x20;

在这种情况下，你可能会给模型一个如下的提示：`从这本书中找出所有关于“全球变暖主要原因”的摘录。确保摘录包含解释所需的所有相关上下文-换句话说，不要提取缺少重要上下文的小片段。`然后模型开始工作，找到了一些摘录，并列出了它们。但是，由于书的内容非常多，模型可能过早地停止搜索，导致遗漏了一些重要的摘录。&#x20;

为了解决这个问题，你可以继续询问模型：`你有没有遗漏任何关于全球变暖主要原因的摘录？请注意不要重复摘录。同时确保摘录包含解释所需的所有上下文 - 换句话说，不要提取缺少重要上下文的小片段。`这样，模型就会再次进行搜索，尝试找出它在前一轮可能遗漏的摘录。通过这种方式，你就可以获得更全面的结果，提高模型的性能。



